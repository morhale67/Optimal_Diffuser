2023-11-05 15:11:04,773 This is a summery of the run:
2023-11-05 15:11:04,773 Batch size for this run: 2
2023-11-05 15:11:04,773 Size of original image: 32 X 32
2023-11-05 15:11:04,773 learning rate: 0.001
2023-11-05 15:11:04,773 number of masks: 204
2023-11-05 15:11:04,773 Compression ratio: 5
2023-11-05 15:11:04,773 epochs : 100
2023-11-05 15:11:04,773 ***************************************************************************


2023-11-05 15:11:04,773 learning rate: 0.001
2023-11-05 15:11:06,954 Epoch number 0, batch number 0/1:       batch loss 0.02437652088701725
2023-11-05 15:11:06,972 Epoch: 1 	Training Loss: 0.024377
2023-11-05 15:11:06,973 Time for epoch 1 : 1 sec
2023-11-05 15:11:06,973 Average PSNR for epoch 1 on training set is 0.000000
2023-11-05 15:11:10,646 Epoch number 1, batch number 0/1:       batch loss 0.02400119975209236
2023-11-05 15:11:10,674 Epoch: 2 	Training Loss: 0.024001
2023-11-05 15:11:10,674 Time for epoch 2 : 3 sec
2023-11-05 15:11:10,674 Average PSNR for epoch 2 on training set is 0.000000
2023-11-05 15:11:13,494 Epoch number 2, batch number 0/1:       batch loss 0.025090372189879417
2023-11-05 15:11:13,543 Epoch: 3 	Training Loss: 0.025090
2023-11-05 15:11:13,543 Time for epoch 3 : 2 sec
2023-11-05 15:11:13,543 Average PSNR for epoch 3 on training set is 0.000000
2023-11-05 15:11:16,955 Epoch number 3, batch number 0/1:       batch loss 0.024503817781805992
2023-11-05 15:11:16,996 Epoch: 4 	Training Loss: 0.024504
2023-11-05 15:11:16,997 Time for epoch 4 : 2 sec
2023-11-05 15:11:16,997 Average PSNR for epoch 4 on training set is 0.000000
2023-11-05 15:11:21,235 Epoch number 4, batch number 0/1:       batch loss 0.02432786487042904
2023-11-05 15:11:21,280 Epoch: 5 	Training Loss: 0.024328
2023-11-05 15:11:21,280 Time for epoch 5 : 3 sec
2023-11-05 15:11:21,280 Average PSNR for epoch 5 on training set is 0.000000
2023-11-05 15:11:25,273 Epoch number 5, batch number 0/1:       batch loss 0.024072593078017235
2023-11-05 15:11:25,317 Epoch: 6 	Training Loss: 0.024073
2023-11-05 15:11:25,318 Time for epoch 6 : 3 sec
2023-11-05 15:11:25,318 Average PSNR for epoch 6 on training set is 0.000000
2023-11-05 15:11:29,077 Epoch number 6, batch number 0/1:       batch loss 0.02368118241429329
2023-11-05 15:11:29,121 Epoch: 7 	Training Loss: 0.023681
2023-11-05 15:11:29,121 Time for epoch 7 : 2 sec
2023-11-05 15:11:29,121 Average PSNR for epoch 7 on training set is 0.000000
2023-11-05 15:11:32,475 Epoch number 7, batch number 0/1:       batch loss 0.024279210716485977
2023-11-05 15:11:32,520 Epoch: 8 	Training Loss: 0.024279
2023-11-05 15:11:32,520 Time for epoch 8 : 2 sec
2023-11-05 15:11:32,520 Average PSNR for epoch 8 on training set is 0.000000
2023-11-05 15:11:35,608 Epoch number 8, batch number 0/1:       batch loss 0.02406959980726242
2023-11-05 15:11:35,652 Epoch: 9 	Training Loss: 0.024070
2023-11-05 15:11:35,652 Time for epoch 9 : 2 sec
2023-11-05 15:11:35,652 Average PSNR for epoch 9 on training set is 0.000000
2023-11-05 15:11:39,479 Epoch number 9, batch number 0/1:       batch loss 0.023923957720398903
2023-11-05 15:11:39,525 Epoch: 10 	Training Loss: 0.023924
2023-11-05 15:11:39,525 Time for epoch 10 : 3 sec
2023-11-05 15:11:39,525 Average PSNR for epoch 10 on training set is 0.000000
2023-11-05 15:11:42,535 Epoch number 10, batch number 0/1:       batch loss 0.02373420260846615
2023-11-05 15:11:42,578 Epoch: 11 	Training Loss: 0.023734
2023-11-05 15:11:42,578 Time for epoch 11 : 2 sec
2023-11-05 15:11:42,578 Average PSNR for epoch 11 on training set is 0.000000
2023-11-05 15:11:45,902 Epoch number 11, batch number 0/1:       batch loss 0.0233099814504385
2023-11-05 15:11:45,944 Epoch: 12 	Training Loss: 0.023310
2023-11-05 15:11:45,944 Time for epoch 12 : 2 sec
2023-11-05 15:11:45,945 Average PSNR for epoch 12 on training set is 0.000000
2023-11-05 15:11:49,048 Epoch number 12, batch number 0/1:       batch loss 0.02281723916530609
2023-11-05 15:11:49,093 Epoch: 13 	Training Loss: 0.022817
2023-11-05 15:11:49,093 Time for epoch 13 : 2 sec
2023-11-05 15:11:49,093 Average PSNR for epoch 13 on training set is 0.000000
2023-11-05 15:11:53,313 Epoch number 13, batch number 0/1:       batch loss 0.023549674078822136
2023-11-05 15:11:53,360 Epoch: 14 	Training Loss: 0.023550
2023-11-05 15:11:53,360 Time for epoch 14 : 3 sec
2023-11-05 15:11:53,360 Average PSNR for epoch 14 on training set is 0.000000
2023-11-05 15:11:56,661 Epoch number 14, batch number 0/1:       batch loss 0.02384055033326149
2023-11-05 15:11:56,707 Epoch: 15 	Training Loss: 0.023841
2023-11-05 15:11:56,707 Time for epoch 15 : 2 sec
2023-11-05 15:11:56,707 Average PSNR for epoch 15 on training set is 0.000000
2023-11-05 15:12:00,205 Epoch number 15, batch number 0/1:       batch loss 0.023910580202937126
2023-11-05 15:12:00,251 Epoch: 16 	Training Loss: 0.023911
2023-11-05 15:12:00,251 Time for epoch 16 : 2 sec
2023-11-05 15:12:00,251 Average PSNR for epoch 16 on training set is 0.000000
2023-11-05 15:12:04,052 Epoch number 16, batch number 0/1:       batch loss 0.023453017696738243
2023-11-05 15:12:04,097 Epoch: 17 	Training Loss: 0.023453
2023-11-05 15:12:04,098 Time for epoch 17 : 3 sec
2023-11-05 15:12:04,098 Average PSNR for epoch 17 on training set is 0.000000
2023-11-05 15:12:07,945 Epoch number 17, batch number 0/1:       batch loss 0.02272668667137623
2023-11-05 15:12:07,987 Epoch: 18 	Training Loss: 0.022727
2023-11-05 15:12:07,987 Time for epoch 18 : 3 sec
2023-11-05 15:12:07,987 Average PSNR for epoch 18 on training set is 0.000000
2023-11-05 15:12:11,785 Epoch number 18, batch number 0/1:       batch loss 0.022806759923696518
2023-11-05 15:12:11,833 Epoch: 19 	Training Loss: 0.022807
2023-11-05 15:12:11,833 Time for epoch 19 : 3 sec
2023-11-05 15:12:11,833 Average PSNR for epoch 19 on training set is 0.000000
2023-11-05 15:12:14,778 Epoch number 19, batch number 0/1:       batch loss 0.023624693974852562
2023-11-05 15:12:14,824 Epoch: 20 	Training Loss: 0.023625
2023-11-05 15:12:14,825 Time for epoch 20 : 2 sec
2023-11-05 15:12:14,825 Average PSNR for epoch 20 on training set is 0.000000
2023-11-05 15:12:19,018 Epoch number 20, batch number 0/1:       batch loss 0.024899249896407127
2023-11-05 15:12:19,065 Epoch: 21 	Training Loss: 0.024899
2023-11-05 15:12:19,065 Time for epoch 21 : 3 sec
2023-11-05 15:12:19,065 Average PSNR for epoch 21 on training set is 0.000000
2023-11-05 15:12:21,941 Epoch number 21, batch number 0/1:       batch loss 0.02479715459048748
2023-11-05 15:12:21,981 Epoch: 22 	Training Loss: 0.024797
2023-11-05 15:12:21,982 Time for epoch 22 : 2 sec
2023-11-05 15:12:21,982 Average PSNR for epoch 22 on training set is 0.000000
2023-11-05 15:12:24,722 Epoch number 22, batch number 0/1:       batch loss 0.02335846982896328
2023-11-05 15:12:24,767 Epoch: 23 	Training Loss: 0.023358
2023-11-05 15:12:24,767 Time for epoch 23 : 2 sec
2023-11-05 15:12:24,767 Average PSNR for epoch 23 on training set is 0.000000
2023-11-05 15:12:28,993 Epoch number 23, batch number 0/1:       batch loss 0.023318955674767494
2023-11-05 15:12:29,040 Epoch: 24 	Training Loss: 0.023319
2023-11-05 15:12:29,040 Time for epoch 24 : 3 sec
2023-11-05 15:12:29,040 Average PSNR for epoch 24 on training set is 0.000000
2023-11-05 15:12:32,238 Epoch number 24, batch number 0/1:       batch loss 0.02291163243353367
2023-11-05 15:12:32,282 Epoch: 25 	Training Loss: 0.022912
2023-11-05 15:12:32,282 Time for epoch 25 : 2 sec
2023-11-05 15:12:32,282 Average PSNR for epoch 25 on training set is 0.000000
2023-11-05 15:12:35,156 Epoch number 25, batch number 0/1:       batch loss 0.024186978116631508
2023-11-05 15:12:35,201 Epoch: 26 	Training Loss: 0.024187
2023-11-05 15:12:35,201 Time for epoch 26 : 2 sec
2023-11-05 15:12:35,201 Average PSNR for epoch 26 on training set is 0.000000
2023-11-05 15:12:38,298 Epoch number 26, batch number 0/1:       batch loss 0.022733058780431747
2023-11-05 15:12:38,345 Epoch: 27 	Training Loss: 0.022733
2023-11-05 15:12:38,345 Time for epoch 27 : 2 sec
2023-11-05 15:12:38,345 Average PSNR for epoch 27 on training set is 0.000000
2023-11-05 15:12:41,493 Epoch number 27, batch number 0/1:       batch loss 0.024713527411222458
2023-11-05 15:12:41,538 Epoch: 28 	Training Loss: 0.024714
2023-11-05 15:12:41,538 Time for epoch 28 : 2 sec
2023-11-05 15:12:41,538 Average PSNR for epoch 28 on training set is 0.000000
2023-11-05 15:12:45,526 Epoch number 28, batch number 0/1:       batch loss 0.02422594651579857
2023-11-05 15:12:45,571 Epoch: 29 	Training Loss: 0.024226
2023-11-05 15:12:45,571 Time for epoch 29 : 3 sec
2023-11-05 15:12:45,571 Average PSNR for epoch 29 on training set is 0.000000
2023-11-05 15:12:48,830 Epoch number 29, batch number 0/1:       batch loss 0.022326532751321793
2023-11-05 15:12:48,875 Epoch: 30 	Training Loss: 0.022327
2023-11-05 15:12:48,875 Time for epoch 30 : 2 sec
2023-11-05 15:12:48,875 Average PSNR for epoch 30 on training set is 0.000000
2023-11-05 15:12:52,311 Epoch number 30, batch number 0/1:       batch loss 0.02412690967321396
2023-11-05 15:12:52,356 Epoch: 31 	Training Loss: 0.024127
2023-11-05 15:12:52,356 Time for epoch 31 : 2 sec
2023-11-05 15:12:52,356 Average PSNR for epoch 31 on training set is 0.000000
2023-11-05 15:12:56,758 Epoch number 31, batch number 0/1:       batch loss 0.023648107424378395
2023-11-05 15:12:56,801 Epoch: 32 	Training Loss: 0.023648
2023-11-05 15:12:56,801 Time for epoch 32 : 3 sec
2023-11-05 15:12:56,801 Average PSNR for epoch 32 on training set is 0.000000
2023-11-05 15:13:00,907 Epoch number 32, batch number 0/1:       batch loss 0.02432241663336754
2023-11-05 15:13:00,950 Epoch: 33 	Training Loss: 0.024322
2023-11-05 15:13:00,950 Time for epoch 33 : 3 sec
2023-11-05 15:13:00,950 Average PSNR for epoch 33 on training set is 0.000000
2023-11-05 15:13:04,798 Epoch number 33, batch number 0/1:       batch loss 0.024532262235879898
2023-11-05 15:13:04,844 Epoch: 34 	Training Loss: 0.024532
2023-11-05 15:13:04,844 Time for epoch 34 : 3 sec
2023-11-05 15:13:04,844 Average PSNR for epoch 34 on training set is 0.000000
2023-11-05 15:13:08,345 Epoch number 34, batch number 0/1:       batch loss 0.025169333443045616
2023-11-05 15:13:08,389 Epoch: 35 	Training Loss: 0.025169
2023-11-05 15:13:08,389 Time for epoch 35 : 2 sec
2023-11-05 15:13:08,390 Average PSNR for epoch 35 on training set is 0.000000
2023-11-05 15:13:11,885 Epoch number 35, batch number 0/1:       batch loss 0.023164622485637665
2023-11-05 15:13:11,923 Epoch: 36 	Training Loss: 0.023165
2023-11-05 15:13:11,923 Time for epoch 36 : 2 sec
2023-11-05 15:13:11,923 Average PSNR for epoch 36 on training set is 0.000000
2023-11-05 15:13:15,552 Epoch number 36, batch number 0/1:       batch loss 0.02322113886475563
2023-11-05 15:13:15,595 Epoch: 37 	Training Loss: 0.023221
2023-11-05 15:13:15,596 Time for epoch 37 : 2 sec
2023-11-05 15:13:15,596 Average PSNR for epoch 37 on training set is 0.000000
2023-11-05 15:13:18,847 Epoch number 37, batch number 0/1:       batch loss 0.02418568544089794
2023-11-05 15:13:18,892 Epoch: 38 	Training Loss: 0.024186
2023-11-05 15:13:18,893 Time for epoch 38 : 2 sec
2023-11-05 15:13:18,893 Average PSNR for epoch 38 on training set is 0.000000
2023-11-05 15:13:22,508 Epoch number 38, batch number 0/1:       batch loss 0.023360904306173325
2023-11-05 15:13:22,554 Epoch: 39 	Training Loss: 0.023361
2023-11-05 15:13:22,554 Time for epoch 39 : 2 sec
2023-11-05 15:13:22,554 Average PSNR for epoch 39 on training set is 0.000000
2023-11-05 15:13:25,755 Epoch number 39, batch number 0/1:       batch loss 0.02348719909787178
2023-11-05 15:13:25,802 Epoch: 40 	Training Loss: 0.023487
2023-11-05 15:13:25,802 Time for epoch 40 : 2 sec
2023-11-05 15:13:25,802 Average PSNR for epoch 40 on training set is 0.000000
2023-11-05 15:13:29,339 Epoch number 40, batch number 0/1:       batch loss 0.02265031635761261
2023-11-05 15:13:29,384 Epoch: 41 	Training Loss: 0.022650
2023-11-05 15:13:29,384 Time for epoch 41 : 2 sec
2023-11-05 15:13:29,384 Average PSNR for epoch 41 on training set is 0.000000
2023-11-05 15:13:33,124 Epoch number 41, batch number 0/1:       batch loss 0.02304471842944622
2023-11-05 15:13:33,166 Epoch: 42 	Training Loss: 0.023045
2023-11-05 15:13:33,166 Time for epoch 42 : 2 sec
2023-11-05 15:13:33,166 Average PSNR for epoch 42 on training set is 0.000000
2023-11-05 15:13:36,399 Epoch number 42, batch number 0/1:       batch loss 0.024426253512501717
2023-11-05 15:13:36,445 Epoch: 43 	Training Loss: 0.024426
2023-11-05 15:13:36,445 Time for epoch 43 : 2 sec
2023-11-05 15:13:36,445 Average PSNR for epoch 43 on training set is 0.000000
2023-11-05 15:13:39,794 Epoch number 43, batch number 0/1:       batch loss 0.024265434592962265
2023-11-05 15:13:39,847 Epoch: 44 	Training Loss: 0.024265
2023-11-05 15:13:39,847 Time for epoch 44 : 2 sec
2023-11-05 15:13:39,847 Average PSNR for epoch 44 on training set is 0.000000
2023-11-05 15:13:43,292 Epoch number 44, batch number 0/1:       batch loss 0.025517279282212257
2023-11-05 15:13:43,339 Epoch: 45 	Training Loss: 0.025517
2023-11-05 15:13:43,339 Time for epoch 45 : 2 sec
2023-11-05 15:13:43,339 Average PSNR for epoch 45 on training set is 0.000000
2023-11-05 15:13:47,395 Epoch number 45, batch number 0/1:       batch loss 0.023587586358189583
2023-11-05 15:13:47,446 Epoch: 46 	Training Loss: 0.023588
2023-11-05 15:13:47,446 Time for epoch 46 : 3 sec
2023-11-05 15:13:47,446 Average PSNR for epoch 46 on training set is 0.000000
2023-11-05 15:13:50,551 Epoch number 46, batch number 0/1:       batch loss 0.02429560199379921
2023-11-05 15:13:50,598 Epoch: 47 	Training Loss: 0.024296
2023-11-05 15:13:50,598 Time for epoch 47 : 2 sec
2023-11-05 15:13:50,598 Average PSNR for epoch 47 on training set is 0.000000
2023-11-05 15:13:54,184 Epoch number 47, batch number 0/1:       batch loss 0.023827102035284042
2023-11-05 15:13:54,230 Epoch: 48 	Training Loss: 0.023827
2023-11-05 15:13:54,230 Time for epoch 48 : 2 sec
2023-11-05 15:13:54,230 Average PSNR for epoch 48 on training set is 0.000000
2023-11-05 15:13:57,760 Epoch number 48, batch number 0/1:       batch loss 0.02283916063606739
2023-11-05 15:13:57,806 Epoch: 49 	Training Loss: 0.022839
2023-11-05 15:13:57,806 Time for epoch 49 : 3 sec
2023-11-05 15:13:57,806 Average PSNR for epoch 49 on training set is 0.000000
2023-11-05 15:14:01,791 Epoch number 49, batch number 0/1:       batch loss 0.022892190143465996
2023-11-05 15:14:01,836 Epoch: 50 	Training Loss: 0.022892
2023-11-05 15:14:01,836 Time for epoch 50 : 3 sec
2023-11-05 15:14:01,836 Average PSNR for epoch 50 on training set is 0.000000
2023-11-05 15:14:05,535 Epoch number 50, batch number 0/1:       batch loss 0.024157943204045296
2023-11-05 15:14:05,581 Epoch: 51 	Training Loss: 0.024158
2023-11-05 15:14:05,581 Time for epoch 51 : 2 sec
2023-11-05 15:14:05,581 Average PSNR for epoch 51 on training set is 0.000000
2023-11-05 15:14:09,403 Epoch number 51, batch number 0/1:       batch loss 0.024138277396559715
2023-11-05 15:14:09,437 Epoch: 52 	Training Loss: 0.024138
2023-11-05 15:14:09,437 Time for epoch 52 : 3 sec
2023-11-05 15:14:09,437 Average PSNR for epoch 52 on training set is 0.000000
2023-11-05 15:14:12,387 Epoch number 52, batch number 0/1:       batch loss 0.024063417688012123
2023-11-05 15:14:12,431 Epoch: 53 	Training Loss: 0.024063
2023-11-05 15:14:12,431 Time for epoch 53 : 2 sec
2023-11-05 15:14:12,431 Average PSNR for epoch 53 on training set is 0.000000
2023-11-05 15:14:15,391 Epoch number 53, batch number 0/1:       batch loss 0.021955691277980804
2023-11-05 15:14:15,434 Epoch: 54 	Training Loss: 0.021956
2023-11-05 15:14:15,434 Time for epoch 54 : 2 sec
2023-11-05 15:14:15,434 Average PSNR for epoch 54 on training set is 0.000000
2023-11-05 15:14:18,986 Epoch number 54, batch number 0/1:       batch loss 0.023103153333067894
2023-11-05 15:14:19,028 Epoch: 55 	Training Loss: 0.023103
2023-11-05 15:14:19,028 Time for epoch 55 : 2 sec
2023-11-05 15:14:19,028 Average PSNR for epoch 55 on training set is 0.000000
2023-11-05 15:14:22,353 Epoch number 55, batch number 0/1:       batch loss 0.022285474464297295
2023-11-05 15:14:22,397 Epoch: 56 	Training Loss: 0.022285
2023-11-05 15:14:22,397 Time for epoch 56 : 2 sec
2023-11-05 15:14:22,397 Average PSNR for epoch 56 on training set is 0.000000
2023-11-05 15:14:25,670 Epoch number 56, batch number 0/1:       batch loss 0.02353617176413536
2023-11-05 15:14:25,706 Epoch: 57 	Training Loss: 0.023536
2023-11-05 15:14:25,706 Time for epoch 57 : 2 sec
2023-11-05 15:14:25,706 Average PSNR for epoch 57 on training set is 0.000000
2023-11-05 15:14:28,400 Epoch number 57, batch number 0/1:       batch loss 0.022306842729449272
2023-11-05 15:14:28,444 Epoch: 58 	Training Loss: 0.022307
2023-11-05 15:14:28,444 Time for epoch 58 : 2 sec
2023-11-05 15:14:28,444 Average PSNR for epoch 58 on training set is 0.000000
2023-11-05 15:14:32,450 Epoch number 58, batch number 0/1:       batch loss 0.022101420909166336
2023-11-05 15:14:32,507 Epoch: 59 	Training Loss: 0.022101
2023-11-05 15:14:32,507 Time for epoch 59 : 3 sec
2023-11-05 15:14:32,507 Average PSNR for epoch 59 on training set is 0.000000
2023-11-05 15:14:35,722 Epoch number 59, batch number 0/1:       batch loss 0.02382943034172058
2023-11-05 15:14:35,766 Epoch: 60 	Training Loss: 0.023829
2023-11-05 15:14:35,766 Time for epoch 60 : 2 sec
2023-11-05 15:14:35,766 Average PSNR for epoch 60 on training set is 0.000000
2023-11-05 15:14:39,250 Epoch number 60, batch number 0/1:       batch loss 0.023468894883990288
2023-11-05 15:14:39,294 Epoch: 61 	Training Loss: 0.023469
2023-11-05 15:14:39,294 Time for epoch 61 : 2 sec
2023-11-05 15:14:39,294 Average PSNR for epoch 61 on training set is 0.000000
2023-11-05 15:14:42,827 Epoch number 61, batch number 0/1:       batch loss 0.023391036316752434
2023-11-05 15:14:42,864 Epoch: 62 	Training Loss: 0.023391
2023-11-05 15:14:42,864 Time for epoch 62 : 3 sec
2023-11-05 15:14:42,864 Average PSNR for epoch 62 on training set is 0.000000
2023-11-05 15:14:46,913 Epoch number 62, batch number 0/1:       batch loss 0.023356255143880844
2023-11-05 15:14:46,958 Epoch: 63 	Training Loss: 0.023356
2023-11-05 15:14:46,958 Time for epoch 63 : 3 sec
2023-11-05 15:14:46,958 Average PSNR for epoch 63 on training set is 0.000000
2023-11-05 15:14:50,768 Epoch number 63, batch number 0/1:       batch loss 0.023489557206630707
2023-11-05 15:14:50,813 Epoch: 64 	Training Loss: 0.023490
2023-11-05 15:14:50,813 Time for epoch 64 : 3 sec
2023-11-05 15:14:50,813 Average PSNR for epoch 64 on training set is 0.000000
2023-11-05 15:14:54,855 Epoch number 64, batch number 0/1:       batch loss 0.022854506969451904
2023-11-05 15:14:54,899 Epoch: 65 	Training Loss: 0.022855
2023-11-05 15:14:54,899 Time for epoch 65 : 3 sec
2023-11-05 15:14:54,899 Average PSNR for epoch 65 on training set is 0.000000
2023-11-05 15:14:58,030 Epoch number 65, batch number 0/1:       batch loss 0.024277955293655396
2023-11-05 15:14:58,075 Epoch: 66 	Training Loss: 0.024278
2023-11-05 15:14:58,075 Time for epoch 66 : 2 sec
2023-11-05 15:14:58,075 Average PSNR for epoch 66 on training set is 0.000000
2023-11-05 15:15:01,452 Epoch number 66, batch number 0/1:       batch loss 0.023524511605501175
2023-11-05 15:15:01,498 Epoch: 67 	Training Loss: 0.023525
2023-11-05 15:15:01,498 Time for epoch 67 : 2 sec
2023-11-05 15:15:01,498 Average PSNR for epoch 67 on training set is 0.000000
2023-11-05 15:15:05,057 Epoch number 67, batch number 0/1:       batch loss 0.023756247013807297
2023-11-05 15:15:05,104 Epoch: 68 	Training Loss: 0.023756
2023-11-05 15:15:05,104 Time for epoch 68 : 2 sec
2023-11-05 15:15:05,104 Average PSNR for epoch 68 on training set is 0.000000
2023-11-05 15:15:08,074 Epoch number 68, batch number 0/1:       batch loss 0.023504354059696198
2023-11-05 15:15:08,122 Epoch: 69 	Training Loss: 0.023504
2023-11-05 15:15:08,122 Time for epoch 69 : 2 sec
2023-11-05 15:15:08,122 Average PSNR for epoch 69 on training set is 0.000000
2023-11-05 15:15:10,958 Epoch number 69, batch number 0/1:       batch loss 0.023213645443320274
2023-11-05 15:15:11,004 Epoch: 70 	Training Loss: 0.023214
2023-11-05 15:15:11,004 Time for epoch 70 : 2 sec
2023-11-05 15:15:11,004 Average PSNR for epoch 70 on training set is 0.000000
2023-11-05 15:15:15,054 Epoch number 70, batch number 0/1:       batch loss 0.023962685838341713
2023-11-05 15:15:15,099 Epoch: 71 	Training Loss: 0.023963
2023-11-05 15:15:15,099 Time for epoch 71 : 3 sec
2023-11-05 15:15:15,099 Average PSNR for epoch 71 on training set is 0.000000
2023-11-05 15:15:19,216 Epoch number 71, batch number 0/1:       batch loss 0.021803729236125946
2023-11-05 15:15:19,263 Epoch: 72 	Training Loss: 0.021804
2023-11-05 15:15:19,263 Time for epoch 72 : 3 sec
2023-11-05 15:15:19,263 Average PSNR for epoch 72 on training set is 0.000000
2023-11-05 15:15:23,346 Epoch number 72, batch number 0/1:       batch loss 0.022951509803533554
2023-11-05 15:15:23,389 Epoch: 73 	Training Loss: 0.022952
2023-11-05 15:15:23,389 Time for epoch 73 : 3 sec
2023-11-05 15:15:23,390 Average PSNR for epoch 73 on training set is 0.000000
2023-11-05 15:15:26,891 Epoch number 73, batch number 0/1:       batch loss 0.024987300857901573
2023-11-05 15:15:26,936 Epoch: 74 	Training Loss: 0.024987
2023-11-05 15:15:26,936 Time for epoch 74 : 2 sec
2023-11-05 15:15:26,936 Average PSNR for epoch 74 on training set is 0.000000
2023-11-05 15:15:31,184 Epoch number 74, batch number 0/1:       batch loss 0.022251665592193604
2023-11-05 15:15:31,229 Epoch: 75 	Training Loss: 0.022252
2023-11-05 15:15:31,230 Time for epoch 75 : 3 sec
2023-11-05 15:15:31,230 Average PSNR for epoch 75 on training set is 0.000000
2023-11-05 15:15:35,254 Epoch number 75, batch number 0/1:       batch loss 0.024358052760362625
2023-11-05 15:15:35,299 Epoch: 76 	Training Loss: 0.024358
2023-11-05 15:15:35,299 Time for epoch 76 : 3 sec
2023-11-05 15:15:35,300 Average PSNR for epoch 76 on training set is 0.000000
2023-11-05 15:15:38,254 Epoch number 76, batch number 0/1:       batch loss 0.023302998393774033
2023-11-05 15:15:38,299 Epoch: 77 	Training Loss: 0.023303
2023-11-05 15:15:38,299 Time for epoch 77 : 2 sec
2023-11-05 15:15:38,299 Average PSNR for epoch 77 on training set is 0.000000
2023-11-05 15:15:41,355 Epoch number 77, batch number 0/1:       batch loss 0.02333587408065796
2023-11-05 15:15:41,399 Epoch: 78 	Training Loss: 0.023336
2023-11-05 15:15:41,400 Time for epoch 78 : 2 sec
2023-11-05 15:15:41,400 Average PSNR for epoch 78 on training set is 0.000000
2023-11-05 15:15:45,511 Epoch number 78, batch number 0/1:       batch loss 0.02262018248438835
2023-11-05 15:15:45,555 Epoch: 79 	Training Loss: 0.022620
2023-11-05 15:15:45,556 Time for epoch 79 : 3 sec
2023-11-05 15:15:45,556 Average PSNR for epoch 79 on training set is 0.000000
2023-11-05 15:15:48,829 Epoch number 79, batch number 0/1:       batch loss 0.022092223167419434
2023-11-05 15:15:48,875 Epoch: 80 	Training Loss: 0.022092
2023-11-05 15:15:48,876 Time for epoch 80 : 2 sec
2023-11-05 15:15:48,876 Average PSNR for epoch 80 on training set is 0.000000
2023-11-05 15:15:51,949 Epoch number 80, batch number 0/1:       batch loss 0.02159232273697853
2023-11-05 15:15:51,995 Epoch: 81 	Training Loss: 0.021592
2023-11-05 15:15:51,995 Time for epoch 81 : 2 sec
2023-11-05 15:15:51,995 Average PSNR for epoch 81 on training set is 0.000000
2023-11-05 15:15:56,002 Epoch number 81, batch number 0/1:       batch loss 0.023266972973942757
2023-11-05 15:15:56,046 Epoch: 82 	Training Loss: 0.023267
2023-11-05 15:15:56,046 Time for epoch 82 : 3 sec
2023-11-05 15:15:56,046 Average PSNR for epoch 82 on training set is 0.000000
2023-11-05 15:15:59,612 Epoch number 82, batch number 0/1:       batch loss 0.021929191425442696
2023-11-05 15:15:59,657 Epoch: 83 	Training Loss: 0.021929
2023-11-05 15:15:59,657 Time for epoch 83 : 3 sec
2023-11-05 15:15:59,658 Average PSNR for epoch 83 on training set is 0.000000
2023-11-05 15:16:03,710 Epoch number 83, batch number 0/1:       batch loss 0.021633010357618332
2023-11-05 15:16:03,753 Epoch: 84 	Training Loss: 0.021633
2023-11-05 15:16:03,753 Time for epoch 84 : 3 sec
2023-11-05 15:16:03,753 Average PSNR for epoch 84 on training set is 0.000000
2023-11-05 15:16:07,089 Epoch number 84, batch number 0/1:       batch loss 0.02288834936916828
2023-11-05 15:16:07,135 Epoch: 85 	Training Loss: 0.022888
2023-11-05 15:16:07,136 Time for epoch 85 : 2 sec
2023-11-05 15:16:07,136 Average PSNR for epoch 85 on training set is 0.000000
2023-11-05 15:16:11,121 Epoch number 85, batch number 0/1:       batch loss 0.022943338379263878
2023-11-05 15:16:11,167 Epoch: 86 	Training Loss: 0.022943
2023-11-05 15:16:11,167 Time for epoch 86 : 3 sec
2023-11-05 15:16:11,167 Average PSNR for epoch 86 on training set is 0.000000
2023-11-05 15:16:14,640 Epoch number 86, batch number 0/1:       batch loss 0.021965431049466133
2023-11-05 15:16:14,696 Epoch: 87 	Training Loss: 0.021965
2023-11-05 15:16:14,696 Time for epoch 87 : 2 sec
2023-11-05 15:16:14,697 Average PSNR for epoch 87 on training set is 0.000000
2023-11-05 15:16:17,896 Epoch number 87, batch number 0/1:       batch loss 0.02467879094183445
2023-11-05 15:16:17,941 Epoch: 88 	Training Loss: 0.024679
2023-11-05 15:16:17,941 Time for epoch 88 : 2 sec
2023-11-05 15:16:17,941 Average PSNR for epoch 88 on training set is 0.000000
2023-11-05 15:16:21,161 Epoch number 88, batch number 0/1:       batch loss 0.022062381729483604
2023-11-05 15:16:21,207 Epoch: 89 	Training Loss: 0.022062
2023-11-05 15:16:21,207 Time for epoch 89 : 2 sec
2023-11-05 15:16:21,208 Average PSNR for epoch 89 on training set is 0.000000
2023-11-05 15:16:24,677 Epoch number 89, batch number 0/1:       batch loss 0.024859879165887833
2023-11-05 15:16:24,720 Epoch: 90 	Training Loss: 0.024860
2023-11-05 15:16:24,720 Time for epoch 90 : 2 sec
2023-11-05 15:16:24,720 Average PSNR for epoch 90 on training set is 0.000000
2023-11-05 15:16:27,846 Epoch number 90, batch number 0/1:       batch loss 0.021993517875671387
2023-11-05 15:16:27,891 Epoch: 91 	Training Loss: 0.021994
2023-11-05 15:16:27,891 Time for epoch 91 : 2 sec
2023-11-05 15:16:27,891 Average PSNR for epoch 91 on training set is 0.000000
2023-11-05 15:16:30,977 Epoch number 91, batch number 0/1:       batch loss 0.02292986959218979
2023-11-05 15:16:31,022 Epoch: 92 	Training Loss: 0.022930
2023-11-05 15:16:31,022 Time for epoch 92 : 2 sec
2023-11-05 15:16:31,022 Average PSNR for epoch 92 on training set is 0.000000
2023-11-05 15:16:34,171 Epoch number 92, batch number 0/1:       batch loss 0.024721652269363403
2023-11-05 15:16:34,215 Epoch: 93 	Training Loss: 0.024722
2023-11-05 15:16:34,215 Time for epoch 93 : 2 sec
2023-11-05 15:16:34,216 Average PSNR for epoch 93 on training set is 0.000000
2023-11-05 15:16:37,157 Epoch number 93, batch number 0/1:       batch loss 0.022160561755299568
2023-11-05 15:16:37,197 Epoch: 94 	Training Loss: 0.022161
2023-11-05 15:16:37,197 Time for epoch 94 : 2 sec
2023-11-05 15:16:37,197 Average PSNR for epoch 94 on training set is 0.000000
2023-11-05 15:16:40,173 Epoch number 94, batch number 0/1:       batch loss 0.02416130341589451
2023-11-05 15:16:40,218 Epoch: 95 	Training Loss: 0.024161
2023-11-05 15:16:40,218 Time for epoch 95 : 2 sec
2023-11-05 15:16:40,218 Average PSNR for epoch 95 on training set is 0.000000
2023-11-05 15:16:43,392 Epoch number 95, batch number 0/1:       batch loss 0.02285139262676239
2023-11-05 15:16:43,441 Epoch: 96 	Training Loss: 0.022851
2023-11-05 15:16:43,441 Time for epoch 96 : 2 sec
2023-11-05 15:16:43,441 Average PSNR for epoch 96 on training set is 0.000000
2023-11-05 15:16:47,965 Epoch number 96, batch number 0/1:       batch loss 0.02461005374789238
2023-11-05 15:16:48,014 Epoch: 97 	Training Loss: 0.024610
2023-11-05 15:16:48,014 Time for epoch 97 : 4 sec
2023-11-05 15:16:48,014 Average PSNR for epoch 97 on training set is 0.000000
2023-11-05 15:16:51,347 Epoch number 97, batch number 0/1:       batch loss 0.02509380504488945
2023-11-05 15:16:51,389 Epoch: 98 	Training Loss: 0.025094
2023-11-05 15:16:51,389 Time for epoch 98 : 3 sec
2023-11-05 15:16:51,389 Average PSNR for epoch 98 on training set is 0.000000
2023-11-05 15:16:54,952 Epoch number 98, batch number 0/1:       batch loss 0.021640175953507423
2023-11-05 15:16:54,993 Epoch: 99 	Training Loss: 0.021640
2023-11-05 15:16:54,993 Time for epoch 99 : 2 sec
2023-11-05 15:16:54,994 Average PSNR for epoch 99 on training set is 0.000000
2023-11-05 15:16:58,715 Epoch number 99, batch number 0/1:       batch loss 0.02341560646891594
2023-11-05 15:16:58,760 Epoch: 100 	Training Loss: 0.023416
2023-11-05 15:16:58,760 Time for epoch 100 : 3 sec
2023-11-05 15:16:58,761 Average PSNR for epoch 100 on training set is 0.000000
2023-11-05 15:17:02,694 Epoch number 100, batch number 0/1:       batch loss 0.023797454312443733
2023-11-05 15:17:03,958 findfont: Font family 'Arial' not found.
2023-11-05 15:17:03,959 findfont: Font family 'Arial' not found.
2023-11-05 15:17:03,959 findfont: Font family 'Times New Roman' not found.
2023-11-05 15:17:03,959 findfont: Font family 'Times New Roman' not found.
2023-11-05 15:17:03,960 findfont: Font family 'Times New Roman' not found.
2023-11-05 15:17:03,973 findfont: Font family 'Arial' not found.
2023-11-05 15:17:03,973 findfont: Font family 'Arial' not found.
2023-11-05 15:17:03,980 findfont: Font family 'Arial' not found.
2023-11-05 15:17:03,984 findfont: Font family 'Times New Roman' not found.
2023-11-05 15:17:03,984 findfont: Font family 'Times New Roman' not found.
2023-11-05 15:17:04,045 findfont: Font family 'Arial' not found.
2023-11-05 15:17:04,052 findfont: Font family 'Arial' not found.
2023-11-05 15:17:04,055 findfont: Font family 'Times New Roman' not found.
2023-11-05 15:17:04,055 findfont: Font family 'Times New Roman' not found.
2023-11-05 15:17:04,061 Run Finished Successfully
